{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6d5b96e-a790-4ee9-b835-f0fee4df3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08c4db0a-519d-43dc-9a33-8a30f582e67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trima\\AppData\\Local\\Temp\\ipykernel_22020\\403236639.py:3: DtypeWarning: Columns (3,7,13,14,17,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  events = pd.read_csv(\"events-1681209680.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (124969, 55)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "devices = pd.read_csv(\"devices-1681209661.csv\")\n",
    "events = pd.read_csv(\"events-1681209680.csv\")\n",
    "manufacturers = pd.read_csv(\"manufacturers-1681209657.csv\")\n",
    "\n",
    "# Merge events with devices\n",
    "df = pd.merge(events, devices, left_on=\"device_id\", right_on=\"id\", how=\"inner\", suffixes=(\"_event\", \"_device\"))\n",
    "\n",
    "# Merge with manufacturers\n",
    "df = pd.merge(df, manufacturers, left_on=\"manufacturer_id\", right_on=\"id\", how=\"inner\", suffixes=(\"\", \"_manufacturer\"))\n",
    "print(\"Shape:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "430dd95e-048c-4be4-8f92-e921fc5f7e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Missing values handled\n",
      "Shape after cleaning: (124969, 55)\n"
     ]
    }
   ],
   "source": [
    "# Make a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1) Handle key categorical columns with specific replacements\n",
    "null_replacements = {\n",
    "    'action': 'No_action',\n",
    "    'determined_cause': 'No_cause',\n",
    "    'reason': 'No_reason',\n",
    "    'status': 'Ongoing'\n",
    "}\n",
    "\n",
    "for col, val in null_replacements.items():\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].fillna(val).replace(['',' '], val)\n",
    "\n",
    "# 2) Handle other object columns (categoricals)\n",
    "for col in df_clean.select_dtypes(include='object').columns:\n",
    "    if col not in null_replacements:\n",
    "        df_clean[col] = df_clean[col].fillna(\"Unclassified\").replace(['',' '], \"Unclassified\")\n",
    "\n",
    "# 3) Handle numeric columns\n",
    "for col in df_clean.select_dtypes(include=['int64','float64']).columns:\n",
    "    df_clean[col] = df_clean[col].fillna(0)\n",
    "\n",
    "print(\"✅ Missing values handled\")\n",
    "print(\"Shape after cleaning:\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f9e28d3-23a2-40e6-a9c0-edede197a5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing rows with both dates missing: 54984\n",
      "Removing low-quality rows: 1042\n",
      "✅ Useless rows removed\n",
      "Shape after filtering: (68943, 55)\n"
     ]
    }
   ],
   "source": [
    "# Step 3a: Drop rows with both key dates missing\n",
    "if 'date_initiated_by_firm' in df_clean.columns and 'date_posted' in df_clean.columns:\n",
    "    mask_dates = (\n",
    "        (df_clean['date_initiated_by_firm'].isin(['Unclassified']) | df_clean['date_initiated_by_firm'].isna()) &\n",
    "        (df_clean['date_posted'].isin(['Unclassified']) | df_clean['date_posted'].isna())\n",
    "    )\n",
    "    print(\"Removing rows with both dates missing:\", mask_dates.sum())\n",
    "    df_clean = df_clean[~mask_dates]\n",
    "\n",
    "# Step 3b: Drop rows with all uninformative fields\n",
    "criteria = (\n",
    "    (df_clean['action_classification'] == 'Unclassified') &\n",
    "    (df_clean['risk_class'] == 'Unclassified') &\n",
    "    (df_clean['reason'] == 'No_reason') &\n",
    "    (df_clean['determined_cause'] == 'No_cause') &\n",
    "    (df_clean['type'] == 'Recall')\n",
    ")\n",
    "print(\"Removing low-quality rows:\", criteria.sum())\n",
    "df_clean = df_clean[~criteria]\n",
    "\n",
    "print(\"✅ Useless rows removed\")\n",
    "print(\"Shape after filtering:\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81117516-3133-49a2-a63d-8839c2adac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Categories normalized\n",
      "Unique values for risk_class: ['Unclassified' '2' '1' '3']\n",
      "Unique values for action_classification: ['Unclassified' 'II' 'III' 'I']\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Normalize categories\n",
    "\n",
    "if 'risk_class' in df_clean.columns:\n",
    "    df_clean['risk_class'] = df_clean['risk_class'].replace({\n",
    "        'Unknown': 'Unclassified',\n",
    "        'Not Classified': 'Unclassified',\n",
    "        'HDE': 'Unclassified'\n",
    "    })\n",
    "\n",
    "if 'action_classification' in df_clean.columns:\n",
    "    df_clean['action_classification'] = df_clean['action_classification'].replace({\n",
    "        'Class 1': 'I', 'Class I': 'I', 'I': 'I',\n",
    "        'Class 2': 'II', 'Class II': 'II', 'II': 'II',\n",
    "        'Class 3': 'III', 'Class III': 'III', 'III': 'III',\n",
    "        'Unknown': 'Unclassified',\n",
    "        'Unclassified Correction': 'Unclassified'\n",
    "    })\n",
    "\n",
    "print(\"✅ Categories normalized\")\n",
    "print(\"Unique values for risk_class:\", df_clean['risk_class'].unique())\n",
    "print(\"Unique values for action_classification:\", df_clean['action_classification'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd40cf62-19ab-470f-9ebc-0605a3919037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_event',\n",
       " 'country_event',\n",
       " 'number_event',\n",
       " 'uid',\n",
       " 'uid_hash',\n",
       " 'slug_event',\n",
       " 'device_id',\n",
       " 'created_at_event',\n",
       " 'updated_at_event',\n",
       " 'id_device',\n",
       " 'manufacturer_id',\n",
       " 'id']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for columns related to event_id\n",
    "[col for col in df_clean.columns if \"event\" in col.lower() or \"id\" in col.lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80dcd7c7-8554-47c3-8875-7b5be5b4a458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Deduplication done\n",
      "Removed duplicates: 0\n",
      "New shape: (68943, 55)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Deduplication using id_event\n",
    "before = df_clean.shape[0]\n",
    "df_clean = df_clean.drop_duplicates(subset=['id_event'])\n",
    "after = df_clean.shape[0]\n",
    "\n",
    "print(\"✅ Deduplication done\")\n",
    "print(\"Removed duplicates:\", before - after)\n",
    "print(\"New shape:\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "026cdcdd-0171-48ca-81d9-4a2c9d6f6490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Low-quality columns dropped\n",
      "New shape: (68943, 46)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Drop very low-quality columns (>90% missing)\n",
    "low_quality_cols = [\n",
    "    'comment',\n",
    "    'action_summary',\n",
    "    'documents',\n",
    "    'create_date',\n",
    "    'action_level',\n",
    "    'date',\n",
    "    'representative',\n",
    "    'target_audience',\n",
    "    'date_updated'\n",
    "]\n",
    "\n",
    "df_clean = df_clean.drop(columns=[col for col in low_quality_cols if col in df_clean.columns])\n",
    "\n",
    "print(\"✅ Low-quality columns dropped\")\n",
    "print(\"New shape:\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99f7a1c4-8d4d-4091-845e-5bcb93e86df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Targets created\n",
      "Multiclass distribution:\n",
      " risk_class_multiclass\n",
      "Unclassified    34260\n",
      "2               26320\n",
      "1                5951\n",
      "3                2412\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Binary distribution:\n",
      " risk_class_binary\n",
      "0    36672\n",
      "1    32271\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Define targets\n",
    "\n",
    "# Ensure risk_class is standardized\n",
    "df_clean['risk_class'] = df_clean['risk_class'].astype(str)\n",
    "\n",
    "# Multiclass target (original)\n",
    "df_clean['risk_class_multiclass'] = df_clean['risk_class']\n",
    "\n",
    "# Binary target: High Risk vs Low Risk\n",
    "df_clean['risk_class_binary'] = df_clean['risk_class'].apply(\n",
    "    lambda x: 1 if x in ['1','2'] else 0\n",
    ")\n",
    "\n",
    "print(\"✅ Targets created\")\n",
    "print(\"Multiclass distribution:\\n\", df_clean['risk_class_multiclass'].value_counts())\n",
    "print(\"\\nBinary distribution:\\n\", df_clean['risk_class_binary'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eac03cf1-eeaf-420e-bc75-831bf8c02c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final cleaned dataset saved as cleaned_dataset_final.csv\n",
      "Final shape: (68943, 48)\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Save final cleaned dataset\n",
    "df_clean.to_csv(\"cleaned_dataset_final.csv\", index=False)\n",
    "\n",
    "print(\"✅ Final cleaned dataset saved as cleaned_dataset_final.csv\")\n",
    "print(\"Final shape:\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d667a-efcb-46ea-8d0f-5e95b395c2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
